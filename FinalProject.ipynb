{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "from os import path\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join('input_data', 'AllStarData.csv')\n",
    "basketball_data = MyPyTable().load_from_file(filename)\n",
    "# set up classifiers\n",
    "knn_classifier = MyKNeighborsClassifier(n_neighbors=10)\n",
    "dummy_classifier = MyDummyClassifier()\n",
    "nb_classifier = MyNaiveBayesClassifier()\n",
    "decision_tree = MyDecisionTreeClassifier()\n",
    "classifiers = [knn_classifier, dummy_classifier, nb_classifier, decision_tree]\n",
    "# Other vars\n",
    "RANDOM_STATE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Effective Field Goal Percentage (eFG%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from table\n",
    "efg_data = basketball_data.get_column('eFG%')\n",
    "allstars = basketball_data.get_column('All-star')\n",
    "# build train and test sets\n",
    "train_sets, test_sets = myevaluation.stratified_kfold_cross_validation(efg_data, allstars, n_splits=10,random_state=RANDOM_STATE)\n",
    "test_length = 0\n",
    "test_answers = []\n",
    "for test in test_sets: \n",
    "    test_answers += [allstars[index] for index in test]\n",
    "    test_length += len(test)\n",
    "# run tests and record results\n",
    "classifier_results = []\n",
    "for classifier in classifiers:\n",
    "    result_set = [[], 0] # [all the predictions, total_number_true] \n",
    "    for train, test in zip(train_sets, test_sets):\n",
    "        # convert the indices to actual samples\n",
    "        x_train = [efg_data[index] for index in train]\n",
    "        y_train = [allstars[index] for index in train]\n",
    "        x_test = [efg_data[index] for index in test]\n",
    "        y_test = [allstars[index] for index in test]\n",
    "        # discretize the data\n",
    "        train_cutoffs = utils.compute_equal_width_cutoffs(x_train, 10)\n",
    "        train_output = [f'X<{train_cutoffs[0]}']\n",
    "        for i, cut in enumerate(train_cutoffs):\n",
    "            if i == len(train_cutoffs)-1:\n",
    "                break\n",
    "            train_output.append(f'{cut}<=X<{train_cutoffs[i+1]}')\n",
    "        train_output.append(f'X>{train_cutoffs[-1]}')\n",
    "        x_train = [[myutils.discretize_ratings_custom(val, train_cutoffs, train_output)] for val in x_train]\n",
    "        x_test = [[myutils.discretize_ratings_custom(val, train_cutoffs, train_output)] for val in x_test]\n",
    "        # fit and predict\n",
    "        classifier.fit(x_train, y_train)\n",
    "        prediction = classifier.predict(x_test)\n",
    "        num_true = myevaluation.accuracy_score(y_test, prediction, normalize=False)\n",
    "        # update counters\n",
    "        result_set[0] += prediction\n",
    "        result_set[1] += num_true\n",
    "    # finalize results\n",
    "    result_set[1] /= test_length\n",
    "    classifier_results.append(result_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.744\n",
      "\tError Rate: 0.256 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall         f1    support\n",
      "---  -----------  --------  ---------  ---------\n",
      "yes     0.333333  0.03125   0.0571429        128\n",
      "no      0.753968  0.979381  0.852018         388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    380      8      388             97.938\n",
      "yes   124      4      128              3.125\n",
      "\n",
      "\n",
      "Dummy--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.752\n",
      "\tError Rate: 0.248 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0                0  0               128\n",
      "no      0.751938         1  0.858407        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    388      0      388                100\n",
      "yes   128      0      128                  0\n",
      "\n",
      "\n",
      "Naive Bayes--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.75\n",
      "\tError Rate: 0.25 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0         0         0               128\n",
      "no      0.751456  0.997423  0.857143        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    387      1      388             99.742\n",
      "yes   128      0      128              0\n",
      "\n",
      "\n",
      "Decision Tree--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.75\n",
      "\tError Rate: 0.25 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0         0         0               128\n",
      "no      0.752918  0.997423  0.858093        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    387      1      388             99.742\n",
      "yes   127      0      127              0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_names = ['KNN', 'Dummy', 'Naive Bayes', 'Decision Tree']\n",
    "headers = ['no', 'yes']\n",
    "myevaluation.print_classifier_results(classifier_names, classifier_results, test_answers, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'list' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9663/557207603.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mallstars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# discretize the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mtrain_cutoffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_equal_width_cutoffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtrain_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf'X<{train_cutoffs[0]}'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cutoffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/NBA-All-Star-CPSC-322/utils.py\u001b[0m in \u001b[0;36mcompute_equal_width_cutoffs\u001b[0;34m(values, num_bins)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_equal_width_cutoffs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0mvalues_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m     \u001b[0mbin_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues_range\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_bins\u001b[0m \u001b[0;31m# float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m# since bin_width is a float, we shouldn't use range() to generate a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'list' and 'list'"
     ]
    }
   ],
   "source": [
    "# build train and test sets\n",
    "train_sets, test_sets = myevaluation.stratified_kfold_cross_validation(basketball_data.data, allstars, n_splits=10,random_state=RANDOM_STATE)\n",
    "test_length = 0\n",
    "test_answers = []\n",
    "for test in test_sets: \n",
    "    test_answers += [allstars[index] for index in test]\n",
    "    test_length += len(test)\n",
    "# run tests and record results\n",
    "classifier_results = []\n",
    "for classifier in classifiers:\n",
    "    result_set = [[], 0] # [all the predictions, total_number_true] \n",
    "    for train, test in zip(train_sets, test_sets):\n",
    "        # convert the indices to actual samples\n",
    "        x_train = [basketball_data.data[index] for index in train]\n",
    "        y_train = [allstars[index] for index in train]\n",
    "        x_test = [basketball_data.data[index] for index in test]\n",
    "        y_test = [allstars[index] for index in test]\n",
    "        # discretize the data\n",
    "        train_cutoffs = utils.compute_equal_width_cutoffs(x_train, 10)\n",
    "        train_output = [f'X<{train_cutoffs[0]}']\n",
    "        for i, cut in enumerate(train_cutoffs):\n",
    "            if i == len(train_cutoffs)-1:\n",
    "                break\n",
    "            train_output.append(f'{cut}<=X<{train_cutoffs[i+1]}')\n",
    "        train_output.append(f'X>{train_cutoffs[-1]}')\n",
    "        x_train = [[myutils.discretize_ratings_custom(val, train_cutoffs, train_output)] for val in x_train]\n",
    "        x_test = [[myutils.discretize_ratings_custom(val, train_cutoffs, train_output)] for val in x_test]\n",
    "        # fit and predict\n",
    "        classifier.fit(x_train, y_train)\n",
    "        prediction = classifier.predict(x_test)\n",
    "        num_true = myevaluation.accuracy_score(y_test, prediction, normalize=False)\n",
    "        # update counters\n",
    "        result_set[0] += prediction\n",
    "        result_set[1] += num_true\n",
    "    # finalize results\n",
    "    result_set[1] /= test_length\n",
    "    classifier_results.append(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = ['KNN', 'Dummy', 'Naive Bayes', 'Decision Tree']\n",
    "headers = ['no', 'yes']\n",
    "myevaluation.print_classifier_results(classifier_names, classifier_results, test_answers, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
