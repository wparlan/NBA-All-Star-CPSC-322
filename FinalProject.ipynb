{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MyKNeighborsClassifier' from 'mysklearn.myclassifiers' (/home/NBA-All-Star-CPSC-322/mysklearn/myclassifiers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7122/2845126466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmysklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyclassifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmysklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmysklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyclassifiers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMyKNeighborsClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyDummyClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyNaiveBayesClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMyDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmysklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyevaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MyKNeighborsClassifier' from 'mysklearn.myclassifiers' (/home/NBA-All-Star-CPSC-322/mysklearn/myclassifiers.py)"
     ]
    }
   ],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "# uncomment once you paste your myclassifiers.py into mysklearn package\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "from os import path\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = path.join('input_data', 'AllStarData.csv')\n",
    "basketball_data = MyPyTable().load_from_file(filename)\n",
    "# set up classifiers\n",
    "knn_classifier = MyKNeighborsClassifier(n_neighbors=10)\n",
    "dummy_classifier = MyDummyClassifier()\n",
    "nb_classifier = MyNaiveBayesClassifier()\n",
    "decision_tree = MyDecisionTreeClassifier()\n",
    "classifiers = [knn_classifier, dummy_classifier, nb_classifier, decision_tree]\n",
    "# Other vars\n",
    "RANDOM_STATE = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the values by column\n",
    "discrete_columns = []\n",
    "for index in range(len(basketball_data.column_names)-1):\n",
    "    curr_column = basketball_data.get_column(index, False)\n",
    "    cutoffs = utils.compute_equal_width_cutoffs(curr_column, 10)\n",
    "    output = myutils.create_output_for_discrete(curr_column, 10)\n",
    "    new_column = [myutils.discretize_ratings_custom(val, cutoffs, output) for val in curr_column]\n",
    "    discrete_columns.append(new_column)\n",
    "# now that the columns are converted, we convert them to rows\n",
    "discrete_data = []\n",
    "allstar_counter = 0\n",
    "for column_index in range(len(discrete_columns[0])):\n",
    "    new_row = []\n",
    "    for row_index in range(len(discrete_columns)):\n",
    "        try:\n",
    "            new_row.append(discrete_columns[row_index][column_index])\n",
    "        except IndexError:\n",
    "            continue\n",
    "    new_row.append(basketball_data.data[allstar_counter][-1])\n",
    "    allstar_counter += 1\n",
    "    discrete_data.append(new_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using Effective Field Goal Percentage (eFG%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve data from table\n",
    "efg_data = [row[2] for row in discrete_data]\n",
    "allstars = [row[-1] for row in discrete_data]\n",
    "# build train and test sets\n",
    "train_sets, test_sets = myevaluation.stratified_kfold_cross_validation(efg_data, allstars, n_splits=10,random_state=RANDOM_STATE)\n",
    "test_length = 0\n",
    "test_answers = []\n",
    "for test in test_sets: \n",
    "    test_answers += [allstars[index] for index in test]\n",
    "    test_length += len(test)\n",
    "# run tests and record results\n",
    "classifier_results = []\n",
    "for classifier in classifiers:\n",
    "    result_set = [[], 0] # [all the predictions, total_number_true] \n",
    "    for train, test in zip(train_sets, test_sets):\n",
    "        # convert the indices to actual samples\n",
    "        x_train = [[efg_data[index]] for index in train]\n",
    "        y_train = [allstars[index] for index in train]\n",
    "        x_test = [[efg_data[index]] for index in test]\n",
    "        y_test = [allstars[index] for index in test]\n",
    "        # fit and predict\n",
    "        classifier.fit(x_train, y_train)\n",
    "        prediction = classifier.predict(x_test)\n",
    "        num_true = myevaluation.accuracy_score(y_test, prediction, normalize=False)\n",
    "        # update counters\n",
    "        result_set[0] += prediction\n",
    "        result_set[1] += num_true\n",
    "    # finalize results\n",
    "    result_set[1] /= test_length\n",
    "    classifier_results.append(result_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.744\n",
      "\tError Rate: 0.256 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall         f1    support\n",
      "---  -----------  --------  ---------  ---------\n",
      "yes     0.333333  0.03125   0.0571429        128\n",
      "no      0.753968  0.979381  0.852018         388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    380      8      388             97.938\n",
      "yes   124      4      128              3.125\n",
      "\n",
      "\n",
      "Dummy--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.752\n",
      "\tError Rate: 0.248 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0                0  0               128\n",
      "no      0.751938         1  0.858407        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    388      0      388                100\n",
      "yes   128      0      128                  0\n",
      "\n",
      "\n",
      "Naive Bayes--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.744\n",
      "\tError Rate: 0.256 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes         0     0         0               128\n",
      "no          0.75  0.989691  0.853333        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    384      4      388             98.969\n",
      "yes   128      0      128              0\n",
      "\n",
      "\n",
      "Decision Tree--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.74\n",
      "\tError Rate: 0.26 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0         0         0               128\n",
      "no      0.750491  0.984536  0.851728        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    382      4      386             98.964\n",
      "yes   127      0      127              0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_names = ['KNN', 'Dummy', 'Naive Bayes', 'Decision Tree']\n",
    "headers = ['no', 'yes']\n",
    "myevaluation.print_classifier_results(classifier_names, classifier_results, test_answers, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Effective Field Goal Percentage\n",
    "The ultimate challenge for every classifier is to beat 75.2% accuracy of the Dummy classifier.  \n",
    "This data is mostly one of two options and that means Dummy is mostly correct.  \n",
    "\n",
    "And no classifier is able to do it.  \n",
    "It's a tie for the silver medal as both Naive Bayes and KNN produce a 74.4% accurate predictions.  \n",
    "This leaves bronze to Decision Tree with 74%, just 0.4% less than silver.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_trait_data = [[row[3], row[4], row[5], row[6], row[7]] for row in discrete_data]\n",
    "# build train and test sets\n",
    "train_sets, test_sets = myevaluation.stratified_kfold_cross_validation(multi_trait_data, allstars, n_splits=10,random_state=RANDOM_STATE)\n",
    "test_length = 0\n",
    "test_answers = []\n",
    "for test in test_sets: \n",
    "    test_answers += [allstars[index] for index in test]\n",
    "    test_length += len(test)\n",
    "# run tests and record results\n",
    "classifier_results = []\n",
    "for classifier in classifiers:\n",
    "    result_set = [[], 0] # [all the predictions, total_number_true] \n",
    "    for train, test in zip(train_sets, test_sets):\n",
    "        # convert the indices to actual samples\n",
    "        x_train = [multi_trait_data[index] for index in train]\n",
    "        y_train = [allstars[index] for index in train]\n",
    "        x_test = [multi_trait_data[index] for index in test]\n",
    "        y_test = [allstars[index] for index in test]\n",
    "        # fit and predict\n",
    "        classifier.fit(x_train, y_train)\n",
    "        prediction = classifier.predict(x_test)\n",
    "        num_true = myevaluation.accuracy_score(y_test, prediction, normalize=False)\n",
    "        # update counters\n",
    "        result_set[0] += prediction\n",
    "        result_set[1] += num_true\n",
    "    # finalize results\n",
    "    result_set[1] /= test_length\n",
    "    classifier_results.append(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.793\n",
      "\tError Rate: 0.207 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0.744186  0.25      0.374269        128\n",
      "no      0.79704   0.971649  0.875726        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    377     11      388             97.165\n",
      "yes    96     32      128             25\n",
      "\n",
      "\n",
      "Dummy--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.752\n",
      "\tError Rate: 0.248 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0                0  0               128\n",
      "no      0.751938         1  0.858407        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    388      0      388                100\n",
      "yes   128      0      128                  0\n",
      "\n",
      "\n",
      "Naive Bayes--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.851\n",
      "\tError Rate: 0.149 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0.72973   0.632812  0.677824        128\n",
      "no      0.883951  0.92268   0.9029          388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    358     30      388             92.268\n",
      "yes    47     81      128             63.281\n",
      "\n",
      "\n",
      "Decision Tree--------------------------\n",
      "Summary:\n",
      "\tAccuracy..: 0.841\n",
      "\tError Rate: 0.159 \n",
      "\n",
      "Precision, Recall, F1:\n",
      "       precision    recall        f1    support\n",
      "---  -----------  --------  --------  ---------\n",
      "yes     0.820513  0.5       0.621359        128\n",
      "no      0.856481  0.953608  0.902439        388 \n",
      "\n",
      "Confusion Matrix:\n",
      "       no    yes    Total    Recognition (%)\n",
      "---  ----  -----  -------  -----------------\n",
      "no    370     14      384             96.354\n",
      "yes    62     64      126             50.794\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier_names = ['KNN', 'Dummy', 'Naive Bayes', 'Decision Tree']\n",
    "headers = ['no', 'yes']\n",
    "myevaluation.print_classifier_results(classifier_names, classifier_results, test_answers, headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Trait Classification Results\n",
    "### These results are great!\n",
    "Dummy has retaken its rightful place as the worst classifier.  \n",
    "Naive Bayes wins with an accuracy of 85.1%, followed by Decision Tree with 84.1% accuracy.  \n",
    "Next is KNN with 79.3% and lastly Dummy with 75.2% accuracy.  \n",
    "\n",
    "This means that these classifiers are proven to be better than pure guessing! Hooray!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discrete_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7122/1600035349.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_traits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiscrete_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# build train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstratified_kfold_cross_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_traits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallstars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRANDOM_STATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_answers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'discrete_data' is not defined"
     ]
    }
   ],
   "source": [
    "all_traits = [row[:-1] for row in discrete_data]\n",
    "# build train and test sets\n",
    "train_sets, test_sets = myevaluation.stratified_kfold_cross_validation(all_traits, allstars, n_splits=10,random_state=RANDOM_STATE)\n",
    "test_length = 0\n",
    "test_answers = []\n",
    "for test in test_sets: \n",
    "    test_answers += [allstars[index] for index in test]\n",
    "    test_length += len(test)\n",
    "# run tests and record results\n",
    "classifier_results = []\n",
    "for classifier in classifiers:\n",
    "    result_set = [[], 0] # [all the predictions, total_number_true] \n",
    "    for train, test in zip(train_sets, test_sets):\n",
    "        # convert the indices to actual samples\n",
    "        x_train = [all_traits[index] for index in train]\n",
    "        y_train = [allstars[index] for index in train]\n",
    "        x_test = [all_traits[index] for index in test]\n",
    "        y_test = [allstars[index] for index in test]\n",
    "        # fit and predict\n",
    "        classifier.fit(x_train, y_train)\n",
    "        prediction = classifier.predict(x_test)\n",
    "        num_true = myevaluation.accuracy_score(y_test, prediction, normalize=False)\n",
    "        # update counters\n",
    "        result_set[0] += prediction\n",
    "        result_set[1] += num_true\n",
    "    # finalize results\n",
    "    result_set[1] /= test_length\n",
    "    classifier_results.append(result_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_names = ['KNN', 'Dummy', 'Naive Bayes', 'Decision Tree']\n",
    "headers = ['no', 'yes']\n",
    "myevaluation.print_classifier_results(classifier_names, classifier_results, test_answers, headers)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
